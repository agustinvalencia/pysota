{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from sklearn.cluster import  OPTICS, DBSCAN,  AgglomerativeClustering\n",
    "from sklearn.cluster._hdbscan.hdbscan import HDBSCAN\n",
    "\n",
    "from pathlib import Path\n",
    "from pysota.process import Persistence\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "results_dir = Path('../results/clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "db = Persistence.load_files(results_dir)\n",
    "print(len(db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [i.abstract for i in db]\n",
    "doc_vectors = [nlp(doc).vector for doc in documents]\n",
    "X = np.array(doc_vectors)\n",
    "\n",
    "eps = .5\n",
    "metric = 'euclidean'\n",
    "\n",
    "# cluster = DBSCAN(eps=eps, min_samples=2)\n",
    "# dbscan = OPTICS(min_samples=2)\n",
    "cluster = AgglomerativeClustering(n_clusters=10, metric=metric, linkage='ward',)\n",
    "# cluster = HDBSCAN(metric='cosine',  max_cluster_size=20)\n",
    "cluster.fit(X)\n",
    "\n",
    "# Group documents by their cluster labels\n",
    "clusters = {}\n",
    "for idx, label in enumerate(cluster.labels_):\n",
    "    clusters.setdefault(label, []).append(db[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of clusters: 10 \n",
      "\n",
      "\n",
      "Cluster 7: 8 documents\n",
      "Cluster 6: 13 documents\n",
      "Cluster 2: 32 documents\n",
      "Cluster 0: 8 documents\n",
      "Cluster 5: 5 documents\n",
      "Cluster 4: 5 documents\n",
      "Cluster 1: 8 documents\n",
      "Cluster 3: 13 documents\n",
      "Cluster 9: 1 documents\n",
      "Cluster 8: 5 documents\n"
     ]
    }
   ],
   "source": [
    "# Print the number of documents in each cluster\n",
    "print(f' Number of clusters: {len(clusters)} \\n\\n')\n",
    "for label, docs in clusters.items():\n",
    "    if label == -1:\n",
    "        print(f\"Noise: {len(docs)} documents\")\n",
    "    else: \n",
    "        print(f\"Cluster {label}: {len(docs)} documents\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of clusters: 10 with eps = 0.5\n",
      "\n",
      "\n",
      "Cluster 7: 8 documents\n",
      "  - Transformation Properties of Learned Visual Representations\n",
      "  - Representations for Stable Off-Policy Reinforcement Learning\n",
      "  - On the Complexity of Representation Learning in Contextual Linear Bandits\n",
      "  - On the Generalization of Representations in Reinforcement Learning\n",
      "  - The Utility of Sparse Representations for Control in Reinforcement Learning\n",
      "  - Learning Sparse Representations Incrementally in Deep Reinforcement Learning\n",
      "  - Revisiting Factorizing Aggregated Posterior in Learning Disentangled Representations\n",
      "  - Representer Theorems for Metric and Preference Learning: A Geometric Perspective\n",
      "\n",
      "\n",
      " ========================================================= \n",
      "\n",
      "\n",
      "Cluster 6: 13 documents\n",
      "  - Speech representation learning: Learning bidirectional encoders with single-view, multi-view, and multi-task methods\n",
      "  - Representation Learning for Natural Language Processing\n",
      "  - Representation Learning: A Statistical Perspective\n",
      "  - A survey on self-supervised methods for visual representation learning\n",
      "  - Unsupervised Representation Learning for Time Series: A Review\n",
      "  - Representation Learning: A Review and New Perspectives\n",
      "  - On the Limits of Learning Representations with Label-Based Supervision\n",
      "  - Self-Supervised Representation Learning for Geographical Data—A Systematic Literature Review\n",
      "  - Learning Actionable Representations with Goal-Conditioned Policies\n",
      "  - An Overview on Data Representation Learning: From Traditional Feature Learning to Recent Deep Learning\n",
      "  - Empirical Evaluation and Theoretical Analysis for Representation Learning: A Survey\n",
      "  - Provable benefits of representation learning\n",
      "  - Applying Self-Supervised Representation Learning for Emotion Recognition Using Physiological Signals\n",
      "\n",
      "\n",
      " ========================================================= \n",
      "\n",
      "\n",
      "Cluster 2: 32 documents\n",
      "  - Diffraction denoising using self‐supervised learning\n",
      "  - Self-supervised Learning Approach for Excavator Activity Recognition Using Contrastive Video Representation\n",
      "  - Learned Camera Gain and Exposure Control for Improved Visual Feature Detection and Matching\n",
      "  - Quantum self-supervised learning\n",
      "  - Spectral Salt-and-Pepper Patch Masking for Self-Supervised Speech Representation Learning\n",
      "  - Self-Supervised Graph Representation Learning via Information Bottleneck\n",
      "  - Boarding for ISS: Imbalanced Self-Supervised: Discovery of a Scaled Autoencoder for Mixed Tabular Datasets\n",
      "  - Contrastive Self-supervised Representation Learning Using Synthetic Data\n",
      "  - Group-based siamese self-supervised learning\n",
      "  - DLR : Toward a deep learned rhythmic representation for music content analysis\n",
      "  - Heuristic Attention Representation Learning for Self-Supervised Pretraining\n",
      "  - Self-Supervised Representation Learning Framework for Remote Physiological Measurement Using Spatiotemporal Augmentation Loss\n",
      "  - Strong Representation Learning for Weakly Supervised Object Detection\n",
      "  - Deep Representation Learning with Part Loss for Person Re-Identification\n",
      "  - Learning Representations by Stochastic Meta-Gradient Descent in Neural Networks\n",
      "  - Exploring self-supervised learning biases for microscopy image representation\n",
      "  - Self-Supervised Representation Learning for Quasi-Simultaneous Arrival Signal Identification Based on Reconnaissance Drones\n",
      "  - Distilling Localization for Self-Supervised Representation Learning\n",
      "  - Self-supervised Discriminative Representation Learning by Fuzzy Autoencoder\n",
      "  - Series2vec: similarity-based self-supervised representation learning for time series classification\n",
      "  - Duplicate Image Representation Based on Semi-Supervised Learning\n",
      "  - Self-Supervised Representation Learning with Meta Comprehensive Regularization\n",
      "  - SRL‐ProtoNet: Self‐supervised representation learning for few‐shot remote sensing scene classification\n",
      "  - Boost Supervised Pretraining for Visual Transfer Learning: Implications of Self-Supervised Contrastive Representation Learning\n",
      "  - Self-Supervised EEG Representation Learning for Robust Emotion Recognition\n",
      "  - Patch-Wise Self-Supervised Visual Representation Learning: A Fine-Grained Approach\n",
      "  - Self-Supervised Learning for Wireless Localization\n",
      "  - Detecting galaxy tidal features using self-supervised representation learning\n",
      "  - Self-supervised representation learning for surgical activity recognition\n",
      "  - Self-Supervised Facial Motion Representation Learning via Contrastive Subclips\n",
      "  - Contrastive self-supervised representation learning without negative samples for multimodal human action recognition\n",
      "  - Suppressing Static Visual Cues via Normalizing Flows for Self-Supervised Video Representation Learning\n",
      "\n",
      "\n",
      " ========================================================= \n",
      "\n",
      "\n",
      "Cluster 0: 8 documents\n",
      "  - Generation-based Multi-view Contrast for Self-supervised Graph Representation Learning\n",
      "  - Non-Parametric Representation Learning with Kernels\n",
      "  - Self-supervised learning for Formosan speech representation and linguistic phylogeny\n",
      "  - GraphCL: Contrastive Self-Supervised Learning of Graph Representations\n",
      "  - Theory of Graph Neural Networks: Representation and Learning\n",
      "  - C$^2$VAE: Gaussian Copula-based VAE Differing Disentangled from Coupled Representations with Contrastive Posterior\n",
      "  - Learning Robust Representations with Graph Denoising Policy Network\n",
      "  - Self-supervised Bipartite Graph Representation Learning: A Dirichlet Max-margin Matrix Factorization Approach\n",
      "\n",
      "\n",
      " ========================================================= \n",
      "\n",
      "\n",
      "Cluster 5: 5 documents\n",
      "  - Deep causal representation learning for unsupervised domain adaptation\n",
      "  - GeomCA: Geometric Evaluation of Data Representations\n",
      "  - Coupled Representation Learning for Domains, Intents and Slots in Spoken Language Understanding\n",
      "  - When Representations Align: Universality in Representation Learning Dynamics\n",
      "  - Image-embodied Knowledge Representation Learning\n",
      "\n",
      "\n",
      " ========================================================= \n",
      "\n",
      "\n",
      "Cluster 4: 5 documents\n",
      "  - Self-Supervised Spatiotemporal Representation Learning by Exploiting Video Continuity\n",
      "  - SW-VAE: Weakly Supervised Learn Disentangled Representation Via Latent Factor Swapping\n",
      "  - Concept-Oriented Deep Learning\n",
      "  - From Centralized to Self-Supervised: Pursuing Realistic Multi-Agent Reinforcement Learning\n",
      "  - Disentangled Generative Graph Representation Learning\n",
      "\n",
      "\n",
      " ========================================================= \n",
      "\n",
      "\n",
      "Cluster 1: 8 documents\n",
      "  - SS-DRPL: self-supervised deep representation pattern learning for voice-based Parkinson's disease detection\n",
      "  - Multi-modal representation learning in retinal imaging using self-supervised learning for enhanced clinical predictions\n",
      "  - Accurate prediction of molecular targets using a self-supervised image representation learning framework\n",
      "  - Cluster-based histopathology phenotype representation learning by self-supervised multi-class-token hierarchical ViT\n",
      "  - Contrastive Learning for Whole Slide Image Representation: A Self-Supervised Approach in Digital Pathology\n",
      "  - MuSe-GNN: Learning Unified Gene Representation From Multimodal Biological Graph Data\n",
      "  - Joint Self-Supervised Image-Volume Representation Learning with Intra-inter Contrastive Clustering\n",
      "  - Multitask joint strategies of self-supervised representation learning on biomedical networks for drug discovery\n",
      "\n",
      "\n",
      " ========================================================= \n",
      "\n",
      "\n",
      "Cluster 3: 13 documents\n",
      "  - Learning Co-Speech Gesture Representations in Dialogue through Contrastive Learning: An Intrinsic Evaluation\n",
      "  - Investigating Simple Object Representations in Model-Free Deep Reinforcement Learning\n",
      "  - DenoSent: A Denoising Objective for Self-Supervised Sentence Representation Learning\n",
      "  - Graph Representation Learning Enhanced Semi-Supervised Feature Selection\n",
      "  - Self-Supervised Learning of Pretext-Invariant Representations\n",
      "  - Fast, Effective, and Self-Supervised: Transforming Masked Language Models into Universal Lexical and Sentence Encoders\n",
      "  - TimesURL: Self-Supervised Contrastive Learning for Universal Time Series Representation Learning\n",
      "  - Rethinking Multi-view Representation Learning via Distilled Disentangling\n",
      "  - Task-Independent Knowledge Makes for Transferable Representations for Generalized Zero-Shot Learning\n",
      "  - Semantically Consistent Multi-view Representation Learning\n",
      "  - Self-Supervised Multi-Label Transformation Prediction for Video Representation Learning\n",
      "  - Grouped Contrastive Learning of Self-Supervised Sentence Representation\n",
      "  - Contrastive Representation Learning for Self-Supervised Taxonomy Completion\n",
      "\n",
      "\n",
      " ========================================================= \n",
      "\n",
      "\n",
      "Cluster 9: 1 documents\n",
      "  - On Representation Learning with Feedback\n",
      "\n",
      "\n",
      " ========================================================= \n",
      "\n",
      "\n",
      "Cluster 8: 5 documents\n",
      "  - Offline Multitask Representation Learning for Reinforcement Learning\n",
      "  - Curious Representation Learning for Embodied Intelligence\n",
      "  - Meta-Learning Representations for Continual Learning\n",
      "  - Self-Supervised Video Representation Learning with Constrained Spatiotemporal Jigsaw\n",
      "  - Learning Portable Representations for High-Level Planning\n",
      "\n",
      "\n",
      " ========================================================= \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the number of documents in each cluster\n",
    "print(f' Number of clusters: {len(clusters)} with eps = {eps}\\n\\n')\n",
    "for label, docs in clusters.items():\n",
    "    if label == -1:\n",
    "        print(f\"Noise: {len(docs)} documents\")\n",
    "    else: \n",
    "        print(f\"Cluster {label}: {len(docs)} documents\")   \n",
    "    for doc in docs:\n",
    "        title = doc.title.replace('\\n', ' ')\n",
    "        print(f\"  - {title}\")\n",
    "    print('\\n\\n ========================================================= \\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Persistence.save_clusters(clusters, Path(f'../results/clustered/{metric}'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
