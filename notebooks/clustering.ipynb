{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from sklearn.cluster import  OPTICS, DBSCAN,  AgglomerativeClustering\n",
    "from sklearn.cluster._hdbscan.hdbscan import HDBSCAN\n",
    "\n",
    "from pathlib import Path\n",
    "from pysota.process import Persistence\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "results_dir = Path('../results/clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "db = Persistence.load_files(results_dir)\n",
    "print(len(db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [i.abstract for i in db]\n",
    "doc_vectors = [nlp(doc).vector for doc in documents]\n",
    "X = np.array(doc_vectors)\n",
    "\n",
    "eps = .5\n",
    "metric = 'euclidean'\n",
    "\n",
    "# cluster = DBSCAN(eps=eps, min_samples=2)\n",
    "# dbscan = OPTICS(min_samples=2)\n",
    "cluster = AgglomerativeClustering(n_clusters=10, metric=metric, linkage='ward')\n",
    "# cluster = HDBSCAN(metric='cosine',  max_cluster_size=20)\n",
    "cluster.fit(X)\n",
    "\n",
    "# Group documents by their cluster labels\n",
    "clusters = {}\n",
    "for idx, label in enumerate(cluster.labels_):\n",
    "    clusters.setdefault(label, []).append(db[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of clusters: 10 \n",
      "\n",
      "\n",
      "Cluster 4: 17 documents\n",
      "Cluster 9: 6 documents\n",
      "Cluster 1: 29 documents\n",
      "Cluster 6: 8 documents\n",
      "Cluster 5: 15 documents\n",
      "Cluster 3: 9 documents\n",
      "Cluster 7: 2 documents\n",
      "Cluster 2: 3 documents\n",
      "Cluster 0: 2 documents\n",
      "Cluster 8: 1 documents\n"
     ]
    }
   ],
   "source": [
    "# Print the number of documents in each cluster\n",
    "print(f' Number of clusters: {len(clusters)} \\n\\n')\n",
    "for label, docs in clusters.items():\n",
    "    if label == -1:\n",
    "        print(f\"Noise: {len(docs)} documents\")\n",
    "    else: \n",
    "        print(f\"Cluster {label}: {len(docs)} documents\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of clusters: 10 with eps = 0.5\n",
      "\n",
      "\n",
      "Cluster 4: 17 documents\n",
      "  - A survey of benchmarking frameworks for reinforcement learning\n",
      "  - The Machine-Learning Approach of Reinforcement Learning\n",
      "  - Quantum reinforcement learning\n",
      "  - Reinforcement Learning: A Survey\n",
      "  - Reinforcement Learning and Machine ethics:a systematic review\n",
      "  - Topological Foundations of Reinforcement Learning\n",
      "  - Motor Control and Reinforcement Learning\n",
      "  - Local Explanations for Reinforcement Learning\n",
      "  - Reinforcement Learning in Robotics\n",
      "  - A Survey of Reinforcement Learning Techniques: Strategies, Recent Development, and Future Directions\n",
      "  - Lexicographic Multi-Objective Reinforcement Learning\n",
      "  - Reinforcement Learning and Causal Models\n",
      "  - Reinforcement Learning\n",
      "  - Statistical learning as reinforcement learning phenomena\n",
      "  - Reinforcement Learning: Connections, Surprises, Challenges\n",
      "  - The Reinforcement Learning Competitions\n",
      "  - Determinantal Reinforcement Learning\n",
      "\n",
      "\n",
      " ========================================================= \n",
      "\n",
      "\n",
      "Cluster 9: 6 documents\n",
      "  - Computational Reinforcement Learning\n",
      "  - DEEP AND REINFORCEMENT LEARNING\n",
      "  - Applications of Deep Reinforcement Learning in Communications and Networking: A Survey\n",
      "  - Optimization for Reinforcement Learning: From Single Agent to Cooperative Agents\n",
      "  - Evolutionary Reinforcement Learning: A Survey\n",
      "  - A Note on Reinforcement Learning\n",
      "\n",
      "\n",
      " ========================================================= \n",
      "\n",
      "\n",
      "Cluster 1: 29 documents\n",
      "  - Reinforcement learning and artificial agency\n",
      "  - Tracking the Race Between Deep Reinforcement Learning and Imitation Learning -- Extended Version\n",
      "  - Reinforcement Learning and Advanced Reinforcement Learning to Improve Autonomous Vehicle Planning\n",
      "  - Reinforcement Learning and Video Games\n",
      "  - Curiosity-driven Exploration in Sparse-reward Multi-agent Reinforcement Learning\n",
      "  - Reinforcement Learning for IoT Security: A Comprehensive Survey\n",
      "  - Active Reinforcement Learning -- A Roadmap Towards Curious Classifier Systems for Self-Adaptation\n",
      "  - Data Valuation for Offline Reinforcement Learning\n",
      "  - Portfolio Optimization using Reinforcement Learning\n",
      "  - Sample Efficient Reinforcement Learning through Learning from Demonstrations in Minecraft\n",
      "  - Opposition-Based Reinforcement Learning\n",
      "  - A View on Deep Reinforcement Learning in System Optimization\n",
      "  - Photonic reinforcement learning based on optoelectronic reservoir computing\n",
      "  - Fine-grained acceleration control for autonomous intersection management using deep reinforcement learning\n",
      "  - A Survey of In-Context Reinforcement Learning\n",
      "  - Placement Optimization with Deep Reinforcement Learning\n",
      "  - Deep Reinforcement Learning Boosted by External Knowledge\n",
      "  - Unsupervised Meta-Learning for Reinforcement Learning\n",
      "  - Meta-Reinforcement Learning Using Model Parameters\n",
      "  - A Deep Reinforcement Learning Strategy for UAV Autonomous Landing on a Platform\n",
      "  - Offline Robot Reinforcement Learning with Uncertainty-Guided Human Expert Sampling\n",
      "  - Reinforcement Teaching\n",
      "  - Teacher-student curriculum learning for reinforcement learning\n",
      "  - Curriculum Learning in Reinforcement Learning\n",
      "  - Poisoning Deep Reinforcement Learning Agents with In-Distribution Triggers\n",
      "  - Pretraining Deep Actor-Critic Reinforcement Learning Algorithms With Expert Demonstrations\n",
      "  - Deep Reinforcement Learning in Medicine\n",
      "  - Bridging the Gap between Reinforcement Learning and Knowledge Representation: A Logical Off- and On-Policy Framework\n",
      "  - Image Classification Using Reinforcement Learning\n",
      "\n",
      "\n",
      " ========================================================= \n",
      "\n",
      "\n",
      "Cluster 6: 8 documents\n",
      "  - Active Perception and Reinforcement Learning\n",
      "  - CertRL: Formalizing Convergence Proofs for Value and Policy Iteration in Coq\n",
      "  - Composable Modular Reinforcement Learning\n",
      "  - Reinforcement Learning the Chromatic Symmetric Function\n",
      "  - A Robotic Model of Hippocampal Reverse Replay for Reinforcement Learning\n",
      "  - Tackling Error Propagation through Reinforcement Learning: A Case of Greedy Dependency Parsing\n",
      "  - Coordinated crawling via reinforcement learning\n",
      "  - Model-assisted Reinforcement Learning of a Quadrotor\n",
      "\n",
      "\n",
      " ========================================================= \n",
      "\n",
      "\n",
      "Cluster 5: 15 documents\n",
      "  - Structured Kernel-Based Reinforcement Learning\n",
      "  - Robust Reinforcement Learning\n",
      "  - Reinforcement Learning with Option Machines\n",
      "  - Hierarchical Reinforcement Learning\n",
      "  - Quantile Reinforcement Learning\n",
      "  - Reinforcement learning utilizes proxemics\n",
      "  - Anderson Acceleration for Reinforcement Learning\n",
      "  - Reinforcement Learning during Locomotion\n",
      "  - Reinforcement Learning State Estimator\n",
      "  - Reinforcement Learning under Threats\n",
      "  - Robust Reinforcement Learning on Graphs for Logistics optimization\n",
      "  - Combining Hebbian and reinforcement learning in a minibrain model\n",
      "  - Deep Reinforcement Learning with Double Q-Learning\n",
      "  - Lipschitz Lifelong Reinforcement Learning\n",
      "  - Scalable Reinforcement Learning-based Neural Architecture Search\n",
      "\n",
      "\n",
      " ========================================================= \n",
      "\n",
      "\n",
      "Cluster 3: 9 documents\n",
      "  - Online Estimation and Inference for Robust Policy Evaluation in Reinforcement Learning\n",
      "  - PGN: A perturbation generation network against deep reinforcement learning\n",
      "  - Regular Reinforcement Learning\n",
      "  - Prioritized Experience-based Reinforcement Learning with Human Guidance for Autonomous Driving\n",
      "  - A Survey of Exploration Methods in Reinforcement Learning\n",
      "  - A Survey on Physics Informed Reinforcement Learning: Review and Open Problems\n",
      "  - Exploration by Distributional Reinforcement Learning\n",
      "  - Explaining Reinforcement Learning with Shapley Values\n",
      "  - Diverse Policies Converge in Reward-free Markov Decision Processe\n",
      "\n",
      "\n",
      " ========================================================= \n",
      "\n",
      "\n",
      "Cluster 7: 2 documents\n",
      "  - Rating-based Reinforcement Learning\n",
      "  - Rating-Based Reinforcement Learning\n",
      "\n",
      "\n",
      " ========================================================= \n",
      "\n",
      "\n",
      "Cluster 2: 3 documents\n",
      "  - Reinforcement Learning and Savings Behavior\n",
      "  - Reinforcement learning in child molesters\n",
      "  - Personality, Reinforcement and Learning\n",
      "\n",
      "\n",
      " ========================================================= \n",
      "\n",
      "\n",
      "Cluster 0: 2 documents\n",
      "  - Reinforcement Learning Configuration Interaction\n",
      "  - Counterexample-Guided Repair of Reinforcement Learning Systems Using Safety Critics\n",
      "\n",
      "\n",
      " ========================================================= \n",
      "\n",
      "\n",
      "Cluster 8: 1 documents\n",
      "  - A proof of convergence of inverse reinforcement learning for multi-objective optimization\n",
      "\n",
      "\n",
      " ========================================================= \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the number of documents in each cluster\n",
    "print(f' Number of clusters: {len(clusters)} with eps = {eps}\\n\\n')\n",
    "for label, docs in clusters.items():\n",
    "    if label == -1:\n",
    "        print(f\"Noise: {len(docs)} documents\")\n",
    "    else: \n",
    "        print(f\"Cluster {label}: {len(docs)} documents\")   \n",
    "    for doc in docs:\n",
    "        title = doc.title.replace('\\n', ' ')\n",
    "        print(f\"  - {title}\")\n",
    "    print('\\n\\n ========================================================= \\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Persistence.save_clusters(clusters, Path(f'../results/clustered/{metric}'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
