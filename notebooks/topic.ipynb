{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pysota.core import Publication\n",
    "from pysota.process import Persistence\n",
    "\n",
    "db: list[Publication] = Persistence.load_files(path=Path('../results/clustered/euclidean'), query_name='cluster_4')\n",
    "print(len(db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import LatentDirichletAllocation\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# # Sample documents\n",
    "# documents = [doc.abstract for doc in db]\n",
    "\n",
    "# # Convert documents into a document-term matrix\n",
    "# vectorizer = CountVectorizer(stop_words='english')\n",
    "# dtm = vectorizer.fit_transform(documents)\n",
    "\n",
    "# # Set the number of topics\n",
    "# n_topics = 10\n",
    "\n",
    "# # Initialize and fit the LDA model\n",
    "# lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "# lda.fit(dtm)\n",
    "\n",
    "# # Display the top words for each topic\n",
    "# n_top_words = 3\n",
    "# feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# for topic_idx, topic in enumerate(lda.components_):\n",
    "#     print(f\"Topic {topic_idx}:\")\n",
    "#     top_features = [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "#     print(\" \".join(top_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def preprocess(text):\n",
    "    # exclude = ['llm', 'llms', 'trust', 'trustworthy', 'trustworthiness', 'ai', 'intelligence', 'data', 'datum']\n",
    "    # exclude = ['relativity', 'quantum', 'theory', 'physic', 'physics']\n",
    "    # exclude = ['reinforcement', 'learning', 'learn', 'algorithm']\n",
    "    exclude = []\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [\n",
    "        token.lemma_ for token in doc\n",
    "        if not token.is_stop and not token.is_punct and token.is_alpha and token.lemma_ not in exclude\n",
    "    ]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# Preprocess each document\n",
    "texts = [preprocess(doc.abstract) for doc in db]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a dictionary and corpus\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Filter out words that occur less than 2 documents, or more than 50% of the documents\n",
    "# dictionary.filter_extremes(no_below=2)\n",
    "\n",
    "# Train the LDA model\n",
    "# Set training parameters\n",
    "num_topics = 6\n",
    "passes = 100\n",
    "\n",
    "# Train the LDA model\n",
    "lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=passes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.031*\"ethic\" + 0.028*\"machine\" + 0.020*\"sl\" + 0.016*\"language\" + 0.012*\"review\"')\n",
      "(1, '0.022*\"approach\" + 0.020*\"action\" + 0.019*\"state\" + 0.015*\"study\" + 0.015*\"space\"')\n",
      "(2, '0.013*\"different\" + 0.013*\"challenge\" + 0.013*\"paper\" + 0.013*\"provide\" + 0.013*\"new\"')\n",
      "(3, '0.032*\"model\" + 0.024*\"system\" + 0.016*\"state\" + 0.013*\"chapter\" + 0.013*\"work\"')\n",
      "(4, '0.002*\"reward\" + 0.002*\"compare\" + 0.002*\"present\" + 0.002*\"action\" + 0.002*\"decision\"')\n",
      "(5, '0.023*\"competition\" + 0.015*\"ai\" + 0.015*\"develop\" + 0.012*\"framework\" + 0.012*\"evaluation\"')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display topics\n",
    "topics = lda_model.print_topics(num_words=5)\n",
    "# topics = lda_model.show_topics()\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.3794625177755074\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score = coherence_model_lda.get_coherence()\n",
    "print(f'Coherence Score: {coherence_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "def lda_topics_to_dataframe(lda_model, num_words=10):\n",
    "    # Extract topics from the LDA model\n",
    "    topics = lda_model.show_topics(num_topics=-1, num_words=num_words, formatted=False)\n",
    "    \n",
    "    # Initialize a list to hold the parsed data\n",
    "    data = []\n",
    "    \n",
    "    # Iterate over each topic\n",
    "    for topic_num, terms in topics:\n",
    "        for term, weight in terms:\n",
    "            data.append([topic_num, term, weight])\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data, columns=['Topic', 'Term', 'Weight'])\n",
    "    \n",
    "    # Sort the DataFrame by Topic and Weight in descending order\n",
    "    df = df.sort_values(by=['Topic', 'Weight'], ascending=[True, False]).reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have an LdaModel object named 'lda_model'\n",
    "df_topics = lda_topics_to_dataframe(lda_model, num_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: ethic, machine, sl, language, review \n",
      "Topic 1: approach, action, state, study, space \n",
      "Topic 2: different, challenge, paper, provide, new \n",
      "Topic 3: model, system, state, chapter, work \n",
      "Topic 4: reward, compare, present, action, decision \n",
      "Topic 5: competition, ai, develop, framework, evaluation \n"
     ]
    }
   ],
   "source": [
    "for topic in df_topics.Topic.unique():\n",
    "    terms = df_topics[df_topics.Topic == topic].Term.tolist()\n",
    "    print(f\"Topic {topic}: {', '.join(terms)} \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
